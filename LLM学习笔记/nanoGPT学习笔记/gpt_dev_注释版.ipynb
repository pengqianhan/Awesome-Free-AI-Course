{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJpXpmjEYC_T"
      },
      "source": [
        "## Building a GPT\n",
        "\n",
        "Companion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5hjCcLDr2WC",
        "outputId": "7c1814ce-a469-4ade-a2f8-8938c505beb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-27 04:03:46--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-07-27 04:03:46 (177 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O6medjfRsLD9"
      },
      "outputs": [],
      "source": [
        "# read it in to inspect it 读取数据集\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWI_VyAsN8F",
        "outputId": "3db8abc0-8cd5-492a-a06f-86bd833fb43b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in characters: \", len(text))##打印数据集的长度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5V0FvqseE0",
        "outputId": "8168e428-94cf-4e91-8efd-9ccdc72ae82a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's look at the first 1000 characters；查看前1000个词\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-Rbyr8sfM8",
        "outputId": "9cb9bdad-9c36-4355-c919-260bc629ef13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "# here are all the unique characters that occur in this text；分析数据集里面出现的不重复的词\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)##65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsSSUC9PRIk0",
        "outputId": "ca96057a-0d21-4622-da87-249aec0a9548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set(text_example): {'h', 'r', 'd', ' ', 'w', 'l', 'e', 'o'}\n",
            "sorted(list(set(text_example))): [' ', 'd', 'e', 'h', 'l', 'o', 'r', 'w']\n",
            " ,d,e,h,l,o,r,w\n"
          ]
        }
      ],
      "source": [
        "## 注释：set 会自动踢出重复的字母,以下是一个例子\n",
        "text_example = 'hello world'\n",
        "print('set(text_example):',set(text_example))\n",
        "print('sorted(list(set(text_example))):',sorted(list(set(text_example))))\n",
        "chars_example = sorted(list(set(text_example)))\n",
        "print(','.join(chars_example))##用字符之间是逗号\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1LKNCgwjj1",
        "outputId": "5d50b27a-f1be-4b5a-bd7c-b754e8d32d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }##字符->索引\n",
        "itos = { i:ch for i,ch in enumerate(chars) }##索引->字符\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers;输入字符串，输出对应的索引\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string； 输入索引，输出对应的字符串\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLqknkFZTb33",
        "outputId": "1a225f38-17cf-4293-b804-b1f9edded79b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chars[46]: h\n",
            "chars[47]: i\n"
          ]
        }
      ],
      "source": [
        "## 注释\n",
        "print('chars[46]:',chars[46])#h\n",
        "print('chars[47]:',chars[47])#i\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJb0OXPwzvqg",
        "outputId": "87e267f0-956a-4c3a-ab39-05f4a2e3ff7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)##64-bit integer (signed) https://pytorch.org/docs/stable/tensor_attributes.html\n",
        "print(data.shape, data.dtype)##==len(text) = 1115394\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f_WIXqxz0lU5"
      },
      "outputs": [],
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5Bj8Y6IAD4",
        "outputId": "dfce8711-c31f-4ecf-ed82-999a806e1ad3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8##训练的字符长度是8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HXDe8vGJCEn",
        "outputId": "badd491d-2ee5-406c-c324-b83255bf091d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
            "y: tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ],
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "print('x:',x)\n",
        "print('y:',y)\n",
        "# print('x:',x)## 注释\n",
        "# print('decode(x.tolist()):',decode(x.tolist()))## 注释\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")\n",
        "    # print(f\"when input is {decode(context.tolist())} the target: {decode([target.item()])}\")## 注释"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OBJpUnZdxBr"
      },
      "source": [
        "\n",
        "数据集拼接示意图"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsyv6L32gqJp"
      },
      "source": [
        "![stack.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3k1Czf7LuA9",
        "outputId": "2cdf5553-599d-4093-f5d0-d4a3800bbf40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs shape:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets shape:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "-------------------------------------------\n",
            "the 0t batch\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "the 1t batch\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "the 2t batch\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "the 3t batch\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))##在（0,len(data)-block_size）之间随机取样4个数\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs shape:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets shape:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('-------------------------------------------')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    print(f'the {b}t batch')\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nql_1ER53oCf",
        "outputId": "cee8280f-d00f-491f-daa1-7784d86f8db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xb shape: torch.Size([4, 8])\n",
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3!dcbf?pGXepydZJSrF$Jrqt!:wwWSzPNxbjPiD&Q!a;yNt$Kr$o-gC$WSjJqfBKBySKtSKpwNNfyl&w:q-jluBatD$Lj;?yzyUca!UQ!vrpxZQgC-hlkq,ptKqHoiX-jjeLJ &slERj KUsBOL!mpJO!zLg'wNfqHAMgq'hZCWhu.W.IBcP \n",
            "RFJ&DEs,nw?pxE?xjNHHVxJ&D&vWWToiERJFuszPyZaNw$\n",
            "EQJMgzaveDDIoiMl&sMHkzdRptRCPVjwW.RSVMjs-bgRkzrBTEa!!oP fRSxq.PLboTMkX'DUYepxIBFAYuxKXe.jeh\n",
            "sa!3MGFrSjuM:wX!?BTMl!.?,M:bQzPHpYfN!Cbo'MmtDxBkDD3SBjyFdmY'DOqkWeRjlxyJB-bVbfd&\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers；每个字符的表示从一个数字变成一个向量\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)# C=vocab_size\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            # print('logits.shape after logits.view in forward:',logits.shape)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            # print('idx.shape:',idx.shape)\n",
        "            logits, loss = self(idx)## targets is None\n",
        "            # print('logits.shape after self:',logits.shape)##(B,t,C)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "print('xb shape:',xb.shape)##(Batch_size, block_size)=(4, 8)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)##torch.Size([32, 65])\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eTyJ8qAaDdiF"
      },
      "outputs": [],
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs4kI8YdEkQj",
        "outputId": "099ed03e-8881-4d9d-dc05-76689f6884ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4712703227996826\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVIDWAZEtjN",
        "outputId": "5c0aafc2-7e12-410a-ea5a-f211bb257527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "NRCEls, theresseys\n",
            "PlorseelapinghiybHen yof GLUCEN t l-t E:\n",
            "I hisgothers je are!-e!\n",
            "QLYotouciullle'z,\n",
            "Thitertho s?\n",
            "NDan'spererfo cist ripl chys er orlese;\n",
            "Yo jehof h hecere ek? wferommot mowo soaf yoit, ince his, t, f at. fal whetrimy bupof tor atha Bu!\n",
            "JOutho f cimimave.\n",
            "NEDUSt cir selle p wie wede\n",
            "Ro n apenor f'Y tover witys an sh d w t e w!\n",
            "CEOntiretoaveE IINpe, theck. cung.\n",
            "ORIsthies hacin benqurd bll, d a r w wistatsowor ath\n",
            "Fivet bloll ang a-I theeancu,\n",
            "LINCI'T:\n",
            "Sarry t I Ane sze t\n",
            "LCKI th\n"
          ]
        }
      ],
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XinV8nmAnmKN"
      },
      "source": [
        "## The mathematical trick in self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tukiH-NbRBhA",
        "outputId": "bfede593-4e91-4263-f976-e407135760d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a: tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ],
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "print('a:',a)\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs_E24uRE8kr",
        "outputId": "f8a9a727-8461-4cfe-b5ed-be548cac1aa1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86NuXX0fn7ps",
        "outputId": "64a3033a-ac3a-495e-f6ae-1a39e9961167"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##  We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "xbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "d-sGh7uXIsVF"
      },
      "outputs": [],
      "source": [
        "# # 注释 torch.tril 用法\n",
        "# weit = torch.tril(torch.ones(4, 4),diagonal=0)#diagonal=1\n",
        "# weit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdOAd6-wXkZ",
        "outputId": "2d5873d9-db43-460b-c57a-37f871211087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ]
        }
      ],
      "source": [
        " # version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "# print('xbow:\\n',xbow[0])\n",
        "# print('xbow2:\\n',xbow2[0])\n",
        "print(torch.allclose(xbow, xbow2))\n",
        "##使用更宽松的容差重新检查\n",
        "print(torch.allclose(xbow, xbow2, rtol=1e-04, atol=1e-07))##https://pytorch.org/docs/stable/generated/torch.allclose.html\n",
        "##rtol (float, optional) – relative tolerance. Default: 1e-05； atol (float, optional) – absolute tolerance. Default: 1e-08"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S51Z5KLFuj4D",
        "outputId": "585073ca-ec61-4b51-8181-75914d1dca12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "最大差异: 3.236345946788788e-08\n",
            "最大差异位置: 批次=1, 时间步=5, 通道=1\n",
            "xbow 在该位置的值: 0.0020199816208332777\n",
            "xbow2 在该位置的值: 0.00201994925737381\n",
            "相对误差: 1.6021660485421307e-05\n"
          ]
        }
      ],
      "source": [
        "## 注释： xbow 和 xbow2 误差分析\n",
        "diff = (xbow - xbow2).abs()\n",
        "max_diff = diff.max()\n",
        "max_diff_indices = diff.argmax()\n",
        "\n",
        "# 将一维索引转换为多维索引\n",
        "B, T, C = diff.shape\n",
        "b = max_diff_indices // (T * C)\n",
        "t = (max_diff_indices % (T * C)) // C\n",
        "c = max_diff_indices % C\n",
        "\n",
        "print(f\"最大差异: {max_diff.item()}\")\n",
        "print(f\"最大差异位置: 批次={b.item()}, 时间步={t.item()}, 通道={c.item()}\")\n",
        "print(f\"xbow 在该位置的值: {xbow[b, t, c].item()}\")\n",
        "print(f\"xbow2 在该位置的值: {xbow2[b, t, c].item()}\")\n",
        "print(f\"相对误差: {(max_diff / xbow[b, t, c]).item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOURrfG-ysoL",
        "outputId": "2864e25a-4b9c-45aa-8c40-d76722314d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tril: tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "wei: tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "torch.allclose(xbow2, xbow3): True\n",
            "torch.allclose(xbow, xbow3): False\n"
          ]
        }
      ],
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "print('tril:',tril)\n",
        "wei = torch.zeros((T,T))\n",
        "# print(wei)\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "print('wei:',wei)\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "print('torch.allclose(xbow2, xbow3):',torch.allclose(xbow2, xbow3))##xbow2 和xbow3 完全一致\n",
        "print('torch.allclose(xbow, xbow3):',torch.allclose(xbow, xbow3))####xbow 和xbow3 稍有不同，参考##xbow 和xbow2 的差异\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "x3b71PnrT6R7"
      },
      "outputs": [],
      "source": [
        "# ttt = torch.ones(4,3,2)\n",
        "# print(ttt.transpose(-2,-1).shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW5rRXWxznAd"
      },
      "source": [
        "$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$\n",
        "\n",
        "from  Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in neural information processing systems 30 (2017)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDarxEWIRMKq",
        "outputId": "4f1fb8d1-9bdf-45e7-839e-bbe0cf9e1254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tril:\n",
            " tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "print('tril:\\n',tril)\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT1hdtzXCjgL",
        "outputId": "9e96c015-dee3-4470-9281-569dc93cb033"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wei[0]##每一行的和为1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5CvobiQ0pLr"
      },
      "source": [
        "Notes:\n",
        "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
        "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
        "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
        "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
        "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4SNbLq5z3oBw"
      },
      "outputs": [],
      "source": [
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "# wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
        "wei = q @ k.transpose(-2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6I9n9IRTSo",
        "outputId": "17302212-03a3-401c-a173-52ced0a41d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0449)\n",
            "tensor(1.0700)\n",
            "tensor(17.4690)\n"
          ]
        }
      ],
      "source": [
        "print(k.var())\n",
        "print(q.var())\n",
        "print(wei.var())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l3c9Knf2xRw"
      },
      "source": [
        "上面的结果显示当之间计算$QK^T$ 时，K和 Q 的方差接近1，但是wei 的方差已经是16左右；当计算  $\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)$ 时，wei 的方差也接近1，这就保持了数据的稳定性。\n",
        "\n",
        "另一个角度解释，当使用$\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)$时，可以避免梯度消失，参考这篇文章[《Transformer Networks: A mathematical explanation why scaling the dot products leads to more stable gradients》](https://towardsdatascience.com/transformer-networks-a-mathematical-explanation-why-scaling-the-dot-products-leads-to-more-stable-414f87391500)\n",
        "\n",
        "详细的数学推导可以参考 [scaling_dot_products.md](nanoGPT学习笔记\\scaling_dot_products.md)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH2y8mY82u1B"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB82yzt44REI",
        "outputId": "25f9b8f0-dcf9-4152-b279-eb06f2ac5bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.1981, 0.1705, 0.2189, 0.1705, 0.2420])\n",
            "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
          ]
        }
      ],
      "source": [
        "##注释 解释不同的 scale 对 softmax 输出的影响\n",
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*0.5, dim=-1))\n",
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1))\n",
        "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1)) # gets too peaky, converges to one-hot\n",
        "##由上面的输出可知，当 scale 越大 的时候，输出就越接近 one-hot 向量，而 one-hot 向量会让Value 值过分的关注少数的token；同时也会引起梯度消失，不利于训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Num7sX9CKOH",
        "outputId": "7266b23d-385c-428b-a6ad-502ae9b455e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LayerNorm1d: # (used to be BatchNorm1d)\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633T2cmnW1uk",
        "outputId": "236ad6dc-ec16-4118-8d8d-4a269ab4e842"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.1469), tensor(0.8803))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9cK9BoXCYb",
        "outputId": "6038b75f-f739-4df0-c99e-92abf9efadeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "dRJH6wM_XFfU"
      },
      "outputs": [],
      "source": [
        "# French to English translation example:\n",
        "\n",
        "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
        "# les réseaux de neurones sont géniaux! <START> neural networks are awesome!<END>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcvKeBXoZFOY"
      },
      "source": [
        "### Full finished code, for reference\n",
        "\n",
        "You may want to refer directly to the git repo instead though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoelkOrFY8bN",
        "outputId": "99a587c0-f095-4ff9-cf8e-977c226cd254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.209729 M parameters\n",
            "step 0: train loss 4.4116, val loss 4.4022\n",
            "step 100: train loss 2.6568, val loss 2.6670\n",
            "step 200: train loss 2.5091, val loss 2.5058\n",
            "step 300: train loss 2.4197, val loss 2.4336\n",
            "step 400: train loss 2.3501, val loss 2.3562\n",
            "step 500: train loss 2.2963, val loss 2.3125\n",
            "step 600: train loss 2.2407, val loss 2.2496\n",
            "step 700: train loss 2.2054, val loss 2.2187\n",
            "step 800: train loss 2.1633, val loss 2.1866\n",
            "step 900: train loss 2.1241, val loss 2.1504\n",
            "step 1000: train loss 2.1036, val loss 2.1306\n",
            "step 1100: train loss 2.0698, val loss 2.1180\n",
            "step 1200: train loss 2.0380, val loss 2.0791\n",
            "step 1300: train loss 2.0248, val loss 2.0634\n",
            "step 1400: train loss 1.9926, val loss 2.0359\n",
            "step 1500: train loss 1.9697, val loss 2.0287\n",
            "step 1600: train loss 1.9627, val loss 2.0477\n",
            "step 1700: train loss 1.9403, val loss 2.0115\n",
            "step 1800: train loss 1.9090, val loss 1.9941\n",
            "step 1900: train loss 1.9092, val loss 1.9858\n",
            "step 2000: train loss 1.8847, val loss 1.9925\n",
            "step 2100: train loss 1.8724, val loss 1.9757\n",
            "step 2200: train loss 1.8580, val loss 1.9594\n",
            "step 2300: train loss 1.8560, val loss 1.9537\n",
            "step 2400: train loss 1.8412, val loss 1.9427\n",
            "step 2500: train loss 1.8141, val loss 1.9402\n",
            "step 2600: train loss 1.8292, val loss 1.9397\n",
            "step 2700: train loss 1.8116, val loss 1.9322\n",
            "step 2800: train loss 1.8032, val loss 1.9218\n",
            "step 2900: train loss 1.8022, val loss 1.9285\n",
            "step 3000: train loss 1.7955, val loss 1.9195\n",
            "step 3100: train loss 1.7672, val loss 1.9192\n",
            "step 3200: train loss 1.7568, val loss 1.9138\n",
            "step 3300: train loss 1.7551, val loss 1.9059\n",
            "step 3400: train loss 1.7549, val loss 1.8945\n",
            "step 3500: train loss 1.7383, val loss 1.8956\n",
            "step 3600: train loss 1.7242, val loss 1.8868\n",
            "step 3700: train loss 1.7273, val loss 1.8822\n",
            "step 3800: train loss 1.7176, val loss 1.8923\n",
            "step 3900: train loss 1.7219, val loss 1.8750\n",
            "step 4000: train loss 1.7131, val loss 1.8603\n",
            "step 4100: train loss 1.7105, val loss 1.8777\n",
            "step 4200: train loss 1.7033, val loss 1.8675\n",
            "step 4300: train loss 1.7038, val loss 1.8556\n",
            "step 4400: train loss 1.7057, val loss 1.8643\n",
            "step 4500: train loss 1.6875, val loss 1.8528\n",
            "step 4600: train loss 1.6887, val loss 1.8405\n",
            "step 4700: train loss 1.6834, val loss 1.8501\n",
            "step 4800: train loss 1.6675, val loss 1.8437\n",
            "step 4900: train loss 1.6684, val loss 1.8407\n",
            "step 4999: train loss 1.6645, val loss 1.8286\n",
            "\n",
            "\n",
            "KING RICHARD II:\n",
            "Shal lifest made to bub, to take Our my dagatants:\n",
            "Whith foul his vetward that a endrer, my fears' to zorm heavens,\n",
            "Oof it heart my would but\n",
            "With ensengmin latest in ov the doest not.\n",
            "\n",
            "WARWICK:\n",
            "Welll now, and thus quechiry: there's speak you love.\n",
            "In Bodiet, and whom the sclittle\n",
            "Enout-now what evily well most rive with is compon to the me\n",
            "Town danters, If so;\n",
            "Ange to shall do aleous, for dear?\n",
            "\n",
            "KING HENRY VI:\n",
            "Hark, but a\n",
            "ards bring Edward?\n",
            "\n",
            "GROKE:\n",
            "As is no Rurnts I am you! who neet.\n",
            "Pom mary thou contrantym so a thense.\n",
            "\n",
            "QUEEN VINCENTIO:\n",
            "O, sir, may in God't well ow, whom confessy.\n",
            "Which migh.\n",
            "\n",
            "ARCHILINIUS:\n",
            "Dithul seaze Peed me: very it passce of's cruport;\n",
            "How what make you fear tals: there loves\n",
            "Tunkistren in deed, is xment.\n",
            "\n",
            "CORIONIUS:\n",
            "What comforts me. I with self From the walt I?\n",
            "\n",
            "GRINION:\n",
            "Which ushold.\n",
            "\n",
            "KING HENRY Gindner:\n",
            "Withrief I doot, is onter now.\n",
            "\n",
            "Securming:\n",
            "Intande whose no crown some Eiverely marry sold;\n",
            "For for me watch the\n",
            "our torguet! Goy, know our her and brut what I, I huself as humsell.\n",
            "\n",
            "APTOLYCUM:\n",
            "Laitance and toarth or word\n",
            "As beherefitions so me worting.\n",
            "\n",
            "CORIOLINA:\n",
            "What a wouldds,\n",
            "An but branedy wouldIng my a canity:\n",
            "Was you be any in Becausing watcess the Regreast men is what see would in thas jury your Hrannertandless;\n",
            "As there'erliacter me band frind through he crown, I she love is stay just torment:\n",
            "Slaw you behoth unserving of vonby the post,\n",
            "Whave baste hold; I they nengety may's fries\n",
            "To there's fince, I heave arrow old,\n",
            "Thee best sincess soul be\n",
            "that Lord, as;\n",
            "River thou a-latsteer:\n",
            "Out.\n",
            "\n",
            "PORALLINA:\n",
            "Where but\n",
            "Braight gentle, drieven the know you\n",
            "for that to this mack a rishn. Prawity arm as is infectely,\n",
            "Ah, sinstats o' no, this send; commant to love,\n",
            "Go fly this fathal\n",
            "I cortuns cold, offrong to old, the courtly thee? before a gace.\n",
            "\n",
            "KING RICHARD III:\n",
            "A life he pusict\n",
            "It. Vitters, and were not fanturs, thy promind thy awonse than a braute comforn,\n",
            "Will Roman! you brain shown'd for a dresss me; he heavison!\n",
            "\n",
            "\n",
            "MENE\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import pdb\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape #(16,32,64)\n",
        "        # pdb.set_trace()\n",
        "        k = self.key(x)   # (B,T,C=head_size=64/4)\n",
        "        q = self.query(x) # (B,T,C=head_size)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('x.shape:',x.shape)##(B,T,C)(16,32,64)\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head ## 64//4\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('x.shape:',x.shape)##（B,T,C）(16,32,64)\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]## # 截取最后block_size个token作为模型输入（滑动窗口机制，避免序列过长\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "undefined.undefined.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
